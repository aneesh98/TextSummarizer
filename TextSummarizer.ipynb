{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSummarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbbJMO6dKrWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17bafa58-30ea-4435-b8fd-16d0febf96b6"
      },
      "source": [
        "### INSTALL MODULES ###\n",
        "%cd /content\n",
        "!pip install HTMLParser\n",
        "!pip install contractions\n",
        "!pip install pprint \n",
        "!git clone -b development https://github.com/clips/pattern\n",
        "!sudo apt-get install libmysqlclient-dev\n",
        "%cd pattern\n",
        "!python3 setup.py install"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Collecting HTMLParser\n",
            "  Downloading https://files.pythonhosted.org/packages/85/d1/46b0a439e88974c99785361069134522dd46012eef9578e1623821368e24/HTMLParser-0.0.2.tar.gz\n",
            "Building wheels for collected packages: HTMLParser\n",
            "  Building wheel for HTMLParser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for HTMLParser: filename=HTMLParser-0.0.2-cp36-none-any.whl size=5984 sha256=164985a917d7d195c18358ba61062fac03878c89b19be17f8c94fc3756b5496b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/a1/d9/1655169e4c4354903ca3adc524b2cfd60d44767144c1faef62\n",
            "Successfully built HTMLParser\n",
            "Installing collected packages: HTMLParser\n",
            "Successfully installed HTMLParser-0.0.2\n",
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/2a/ba0a3812e2a1de2cc4ee0ded0bdb750a7cef1631c13c78a4fc4ab042adec/contractions-0.0.21-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.21\n",
            "Collecting pprint\n",
            "  Downloading https://files.pythonhosted.org/packages/99/12/b6383259ef85c2b942ab9135f322c0dce83fdca8600d87122d2b0181451f/pprint-0.1.tar.gz\n",
            "Building wheels for collected packages: pprint\n",
            "  Building wheel for pprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pprint: filename=pprint-0.1-cp36-none-any.whl size=1250 sha256=bd69ecb233e03f8e95a7517c3210be1fa953552961784c15b121ad89fe9d1c2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d4/c6/16a6495aecc1bda5d5857bd036efd50617789ba9bea4a05124\n",
            "Successfully built pprint\n",
            "Installing collected packages: pprint\n",
            "Successfully installed pprint-0.1\n",
            "Cloning into 'pattern'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 10986 (delta 12), reused 17 (delta 6), pack-reused 10953\u001b[K\n",
            "Receiving objects: 100% (10986/10986), 51.10 MiB | 22.42 MiB/s, done.\n",
            "Resolving deltas: 100% (7290/7290), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libmysqlclient-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 1,160 kB of archives.\n",
            "After this operation, 6,995 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmysqlclient-dev amd64 5.7.27-0ubuntu0.18.04.1 [1,160 kB]\n",
            "Fetched 1,160 kB in 1s (1,256 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libmysqlclient-dev.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../libmysqlclient-dev_5.7.27-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libmysqlclient-dev (5.7.27-0ubuntu0.18.04.1) ...\n",
            "Setting up libmysqlclient-dev (5.7.27-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/pattern\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating Pattern.egg-info\n",
            "writing Pattern.egg-info/PKG-INFO\n",
            "writing dependency_links to Pattern.egg-info/dependency_links.txt\n",
            "writing requirements to Pattern.egg-info/requires.txt\n",
            "writing top-level names to Pattern.egg-info/top_level.txt\n",
            "writing manifest file 'Pattern.egg-info/SOURCES.txt'\n",
            "writing manifest file 'Pattern.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/pattern\n",
            "copying pattern/__init__.py -> build/lib/pattern\n",
            "copying pattern/metrics.py -> build/lib/pattern\n",
            "copying pattern/helpers.py -> build/lib/pattern\n",
            "creating build/lib/pattern/text\n",
            "copying pattern/text/__init__.py -> build/lib/pattern/text\n",
            "copying pattern/text/search.py -> build/lib/pattern/text\n",
            "copying pattern/text/tree.py -> build/lib/pattern/text\n",
            "creating build/lib/pattern/web\n",
            "copying pattern/web/api.py -> build/lib/pattern/web\n",
            "copying pattern/web/utils.py -> build/lib/pattern/web\n",
            "copying pattern/web/__init__.py -> build/lib/pattern/web\n",
            "creating build/lib/pattern/web/cache\n",
            "copying pattern/web/cache/__init__.py -> build/lib/pattern/web/cache\n",
            "creating build/lib/pattern/web/imap\n",
            "copying pattern/web/imap/__init__.py -> build/lib/pattern/web/imap\n",
            "creating build/lib/pattern/web/locale\n",
            "copying pattern/web/locale/__init__.py -> build/lib/pattern/web/locale\n",
            "creating build/lib/pattern/web/oauth\n",
            "copying pattern/web/oauth/__init__.py -> build/lib/pattern/web/oauth\n",
            "creating build/lib/pattern/db\n",
            "copying pattern/db/__init__.py -> build/lib/pattern/db\n",
            "creating build/lib/pattern/text/de\n",
            "copying pattern/text/de/__main__.py -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/__init__.py -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/inflect.py -> build/lib/pattern/text/de\n",
            "creating build/lib/pattern/text/en\n",
            "copying pattern/text/en/inflect_quantify.py -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/__main__.py -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/__init__.py -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/modality.py -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/inflect.py -> build/lib/pattern/text/en\n",
            "creating build/lib/pattern/text/en/wordlist\n",
            "copying pattern/text/en/wordlist/__init__.py -> build/lib/pattern/text/en/wordlist\n",
            "creating build/lib/pattern/text/en/wordnet\n",
            "copying pattern/text/en/wordnet/__init__.py -> build/lib/pattern/text/en/wordnet\n",
            "creating build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/__main__.py -> build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/__init__.py -> build/lib/pattern/text/ru\n",
            "creating build/lib/pattern/text/ru/wordlist\n",
            "copying pattern/text/ru/wordlist/__init__.py -> build/lib/pattern/text/ru/wordlist\n",
            "creating build/lib/pattern/text/es\n",
            "copying pattern/text/es/__main__.py -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/__init__.py -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/inflect.py -> build/lib/pattern/text/es\n",
            "creating build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/__main__.py -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/__init__.py -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/inflect.py -> build/lib/pattern/text/fr\n",
            "creating build/lib/pattern/text/it\n",
            "copying pattern/text/it/__main__.py -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/__init__.py -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/inflect.py -> build/lib/pattern/text/it\n",
            "creating build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/__main__.py -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/__init__.py -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/inflect.py -> build/lib/pattern/text/nl\n",
            "creating build/lib/pattern/vector\n",
            "copying pattern/vector/stemmer.py -> build/lib/pattern/vector\n",
            "copying pattern/vector/__init__.py -> build/lib/pattern/vector\n",
            "creating build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/liblinearutil.py -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/liblinear.py -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/libsvmutil.py -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/__init__.py -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/libsvm.py -> build/lib/pattern/vector/svm\n",
            "creating build/lib/pattern/graph\n",
            "copying pattern/graph/commonsense.py -> build/lib/pattern/graph\n",
            "copying pattern/graph/__init__.py -> build/lib/pattern/graph\n",
            "creating build/lib/pattern/server\n",
            "copying pattern/server/__init__.py -> build/lib/pattern/server\n",
            "copying pattern/canvas.js -> build/lib/pattern\n",
            "copying pattern/text/de/de-context.txt -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/de-morphology.txt -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/de-lexicon.txt -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/de-verbs.txt -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/de-spelling.txt -> build/lib/pattern/text/de\n",
            "copying pattern/text/de/de-frequency.txt -> build/lib/pattern/text/de\n",
            "copying pattern/text/en/en-frequency.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-lexicon.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-verbs.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-entities.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-context.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-morphology.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-spelling.txt -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-sentiment.xml -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/en-model.slp -> build/lib/pattern/text/en\n",
            "copying pattern/text/en/wordlist/stopwords.txt -> build/lib/pattern/text/en/wordlist\n",
            "copying pattern/text/en/wordlist/academic.txt -> build/lib/pattern/text/en/wordlist\n",
            "copying pattern/text/en/wordlist/profanity.txt -> build/lib/pattern/text/en/wordlist\n",
            "copying pattern/text/en/wordlist/time.txt -> build/lib/pattern/text/en/wordlist\n",
            "copying pattern/text/en/wordlist/basic.txt -> build/lib/pattern/text/en/wordlist\n",
            "copying pattern/text/en/wordnet/resnik-ic3.txt -> build/lib/pattern/text/en/wordnet\n",
            "copying pattern/text/en/wordnet/resnik-ic2.txt -> build/lib/pattern/text/en/wordnet\n",
            "creating build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/index.adv -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/index.sense -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/data.adj -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/index.adj -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/data.verb -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/data.noun2 -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/index.verb -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/LICENSE.txt -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/lexnames -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/data.noun1 -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/index.noun -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/index.32 -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/en/wordnet/dict/data.adv -> build/lib/pattern/text/en/wordnet/dict\n",
            "copying pattern/text/ru/ru-spelling.txt -> build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/ru-entities.txt -> build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/ru-frequency.txt -> build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/ru-lexicon.txt -> build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/ru-model.slp -> build/lib/pattern/text/ru\n",
            "copying pattern/text/ru/wordlist/stopwords.txt -> build/lib/pattern/text/ru/wordlist\n",
            "copying pattern/text/es/es-verbs.txt -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/es-spelling.txt -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/es-morphology.txt -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/es-context.txt -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/es-frequency.txt -> build/lib/pattern/text/es\n",
            "copying pattern/text/es/es-lexicon.txt -> build/lib/pattern/text/es\n",
            "copying pattern/text/fr/fr-morphology.txt -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/fr-context.txt -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/fr-frequency.txt -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/fr-lexicon.txt -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/fr-spelling.txt -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/fr-verbs.txt -> build/lib/pattern/text/fr\n",
            "copying pattern/text/fr/fr-sentiment.xml -> build/lib/pattern/text/fr\n",
            "copying pattern/text/it/it-spelling.txt -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/it-context.txt -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/it-morphology.txt -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/it-frequency.txt -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/it-lexicon.txt -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/it-verbs.txt -> build/lib/pattern/text/it\n",
            "copying pattern/text/it/it-sentiment.xml -> build/lib/pattern/text/it\n",
            "copying pattern/text/nl/nl-frequency.txt -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/nl-lexicon.txt -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/nl-morphology.txt -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/nl-verbs.txt -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/nl-spelling.txt -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/nl-context.txt -> build/lib/pattern/text/nl\n",
            "copying pattern/text/nl/nl-sentiment.xml -> build/lib/pattern/text/nl\n",
            "copying pattern/vector/stopwords-nl.txt -> build/lib/pattern/vector\n",
            "copying pattern/vector/stopwords-en.txt -> build/lib/pattern/vector\n",
            "copying pattern/vector/stopwords-es.txt -> build/lib/pattern/vector\n",
            "copying pattern/vector/stopwords-fr.txt -> build/lib/pattern/vector\n",
            "copying pattern/vector/stopwords-de.txt -> build/lib/pattern/vector\n",
            "copying pattern/vector/svm/INSTALL.txt -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/COPYRIGHT-liblinear.txt -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/COPYRIGHT-libsvm.txt -> build/lib/pattern/vector/svm\n",
            "copying pattern/vector/svm/README.txt -> build/lib/pattern/vector/svm\n",
            "copying pattern/graph/graph.js -> build/lib/pattern/graph\n",
            "copying pattern/graph/commonsense.csv -> build/lib/pattern/graph\n",
            "creating build/lib/pattern/server/static\n",
            "copying pattern/server/static/robots.txt -> build/lib/pattern/server/static\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pattern\n",
            "copying build/lib/pattern/helpers.py -> build/bdist.linux-x86_64/egg/pattern\n",
            "creating build/bdist.linux-x86_64/egg/pattern/web\n",
            "copying build/lib/pattern/web/api.py -> build/bdist.linux-x86_64/egg/pattern/web\n",
            "copying build/lib/pattern/web/utils.py -> build/bdist.linux-x86_64/egg/pattern/web\n",
            "creating build/bdist.linux-x86_64/egg/pattern/web/locale\n",
            "copying build/lib/pattern/web/locale/__init__.py -> build/bdist.linux-x86_64/egg/pattern/web/locale\n",
            "copying build/lib/pattern/web/__init__.py -> build/bdist.linux-x86_64/egg/pattern/web\n",
            "creating build/bdist.linux-x86_64/egg/pattern/web/imap\n",
            "copying build/lib/pattern/web/imap/__init__.py -> build/bdist.linux-x86_64/egg/pattern/web/imap\n",
            "creating build/bdist.linux-x86_64/egg/pattern/web/cache\n",
            "copying build/lib/pattern/web/cache/__init__.py -> build/bdist.linux-x86_64/egg/pattern/web/cache\n",
            "creating build/bdist.linux-x86_64/egg/pattern/web/oauth\n",
            "copying build/lib/pattern/web/oauth/__init__.py -> build/bdist.linux-x86_64/egg/pattern/web/oauth\n",
            "copying build/lib/pattern/canvas.js -> build/bdist.linux-x86_64/egg/pattern\n",
            "creating build/bdist.linux-x86_64/egg/pattern/server\n",
            "creating build/bdist.linux-x86_64/egg/pattern/server/static\n",
            "copying build/lib/pattern/server/static/robots.txt -> build/bdist.linux-x86_64/egg/pattern/server/static\n",
            "copying build/lib/pattern/server/__init__.py -> build/bdist.linux-x86_64/egg/pattern/server\n",
            "copying build/lib/pattern/__init__.py -> build/bdist.linux-x86_64/egg/pattern\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-sentiment.xml -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-context.txt -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-morphology.txt -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/it-verbs.txt -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/it/inflect.py -> build/bdist.linux-x86_64/egg/pattern/text/it\n",
            "copying build/lib/pattern/text/search.py -> build/bdist.linux-x86_64/egg/pattern/text\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/de-context.txt -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/de-morphology.txt -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/de-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/de-verbs.txt -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/de-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/de-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "copying build/lib/pattern/text/de/inflect.py -> build/bdist.linux-x86_64/egg/pattern/text/de\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/es-verbs.txt -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/es-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/es-morphology.txt -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/es-context.txt -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/es-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/es-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "copying build/lib/pattern/text/es/inflect.py -> build/bdist.linux-x86_64/egg/pattern/text/es\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/ru/wordlist\n",
            "copying build/lib/pattern/text/ru/wordlist/stopwords.txt -> build/bdist.linux-x86_64/egg/pattern/text/ru/wordlist\n",
            "copying build/lib/pattern/text/ru/wordlist/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/ru/wordlist\n",
            "copying build/lib/pattern/text/ru/ru-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/ru/ru-entities.txt -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/ru/ru-model.slp -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/ru/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/ru/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/ru/ru-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/ru/ru-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/ru\n",
            "copying build/lib/pattern/text/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text\n",
            "copying build/lib/pattern/text/tree.py -> build/bdist.linux-x86_64/egg/pattern/text\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-morphology.txt -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-context.txt -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-sentiment.xml -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/fr-verbs.txt -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "copying build/lib/pattern/text/fr/inflect.py -> build/bdist.linux-x86_64/egg/pattern/text/fr\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-sentiment.xml -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-morphology.txt -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-verbs.txt -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/nl-context.txt -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "copying build/lib/pattern/text/nl/inflect.py -> build/bdist.linux-x86_64/egg/pattern/text/nl\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/wordlist/stopwords.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/wordlist/academic.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/wordlist/profanity.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/wordlist/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/wordlist/time.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/wordlist/basic.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordlist\n",
            "copying build/lib/pattern/text/en/en-sentiment.xml -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-frequency.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-lexicon.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/inflect_quantify.py -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-verbs.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-entities.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-context.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-morphology.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/__main__.py -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/en/wordnet\n",
            "copying build/lib/pattern/text/en/wordnet/resnik-ic3.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet\n",
            "copying build/lib/pattern/text/en/wordnet/resnik-ic2.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet\n",
            "creating build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/index.adv -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/index.sense -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/data.adj -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/index.adj -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/data.verb -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/data.noun2 -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/index.verb -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/LICENSE.txt -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/lexnames -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/data.noun1 -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/index.noun -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/index.32 -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/dict/data.adv -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/dict\n",
            "copying build/lib/pattern/text/en/wordnet/__init__.py -> build/bdist.linux-x86_64/egg/pattern/text/en/wordnet\n",
            "copying build/lib/pattern/text/en/en-spelling.txt -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/modality.py -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/en-model.slp -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/text/en/inflect.py -> build/bdist.linux-x86_64/egg/pattern/text/en\n",
            "copying build/lib/pattern/metrics.py -> build/bdist.linux-x86_64/egg/pattern\n",
            "creating build/bdist.linux-x86_64/egg/pattern/graph\n",
            "copying build/lib/pattern/graph/commonsense.py -> build/bdist.linux-x86_64/egg/pattern/graph\n",
            "copying build/lib/pattern/graph/graph.js -> build/bdist.linux-x86_64/egg/pattern/graph\n",
            "copying build/lib/pattern/graph/__init__.py -> build/bdist.linux-x86_64/egg/pattern/graph\n",
            "copying build/lib/pattern/graph/commonsense.csv -> build/bdist.linux-x86_64/egg/pattern/graph\n",
            "creating build/bdist.linux-x86_64/egg/pattern/db\n",
            "copying build/lib/pattern/db/__init__.py -> build/bdist.linux-x86_64/egg/pattern/db\n",
            "creating build/bdist.linux-x86_64/egg/pattern/vector\n",
            "copying build/lib/pattern/vector/stopwords-nl.txt -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "copying build/lib/pattern/vector/stemmer.py -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "copying build/lib/pattern/vector/stopwords-en.txt -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "creating build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/INSTALL.txt -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/COPYRIGHT-liblinear.txt -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/COPYRIGHT-libsvm.txt -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/liblinearutil.py -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/liblinear.py -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/libsvmutil.py -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/__init__.py -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/README.txt -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/svm/libsvm.py -> build/bdist.linux-x86_64/egg/pattern/vector/svm\n",
            "copying build/lib/pattern/vector/stopwords-es.txt -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "copying build/lib/pattern/vector/stopwords-fr.txt -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "copying build/lib/pattern/vector/__init__.py -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "copying build/lib/pattern/vector/stopwords-de.txt -> build/bdist.linux-x86_64/egg/pattern/vector\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/helpers.py to helpers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/api.py to api.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/locale/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/imap/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/cache/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/web/oauth/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/server/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/it/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/it/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/it/inflect.py to inflect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/search.py to search.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/de/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/de/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/de/inflect.py to inflect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/es/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/es/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/es/inflect.py to inflect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/ru/wordlist/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/ru/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/ru/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/tree.py to tree.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/fr/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/fr/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/fr/inflect.py to inflect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/nl/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/nl/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/nl/inflect.py to inflect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/wordlist/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/inflect_quantify.py to inflect_quantify.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/wordnet/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/modality.py to modality.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/text/en/inflect.py to inflect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/metrics.py to metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/graph/commonsense.py to commonsense.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/graph/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/db/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/stemmer.py to stemmer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/svm/liblinearutil.py to liblinearutil.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/svm/liblinear.py to liblinear.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/svm/libsvmutil.py to libsvmutil.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/svm/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/svm/libsvm.py to libsvm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pattern/vector/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying Pattern.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying Pattern.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying Pattern.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying Pattern.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying Pattern.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying Pattern.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating dist\n",
            "creating 'dist/Pattern-3.6.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing Pattern-3.6.1-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/Pattern-3.6.1-py3.6.egg\n",
            "Extracting Pattern-3.6.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding Pattern 3.6.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Pattern-3.6.1-py3.6.egg\n",
            "Processing dependencies for Pattern==3.6.1\n",
            "Searching for cherrypy\n",
            "Reading https://pypi.org/simple/cherrypy/\n",
            "Downloading https://files.pythonhosted.org/packages/79/3f/181e2ffaa923b2989ec8c770d6fb7c341b2b11ad44c6cf5241dd2ce50118/CherryPy-18.3.0-py2.py3-none-any.whl#sha256=033368d25fcc6bca143e7efe9adbfd3a6d91cc0d90c37a649261935f116aafab\n",
            "Best match: CherryPy 18.3.0\n",
            "Processing CherryPy-18.3.0-py2.py3-none-any.whl\n",
            "Installing CherryPy-18.3.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/CherryPy-18.3.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding CherryPy 18.3.0 to easy-install.pth file\n",
            "Installing cherryd script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/CherryPy-18.3.0-py3.6.egg\n",
            "Searching for python-docx\n",
            "Reading https://pypi.org/simple/python-docx/\n",
            "Downloading https://files.pythonhosted.org/packages/e4/83/c66a1934ed5ed8ab1dbb9931f1779079f8bca0f6bbc5793c06c4b5e7d671/python-docx-0.8.10.tar.gz#sha256=bc76ecac6b2d00ce6442a69d03a6f35c71cd72293cd8405a7472dfe317920024\n",
            "Best match: python-docx 0.8.10\n",
            "Processing python-docx-0.8.10.tar.gz\n",
            "Writing /tmp/easy_install-opquv528/python-docx-0.8.10/setup.cfg\n",
            "Running python-docx-0.8.10/setup.py -q bdist_egg --dist-dir /tmp/easy_install-opquv528/python-docx-0.8.10/egg-dist-tmp-cb8ioeu2\n",
            "no previously-included directories found matching 'docs/.build'\n",
            "warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
            "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "docx.__pycache__.api.cpython-36: module references __file__\n",
            "docx.parts.__pycache__.hdrftr.cpython-36: module references __file__\n",
            "docx.parts.__pycache__.settings.cpython-36: module references __file__\n",
            "docx.parts.__pycache__.styles.cpython-36: module references __file__\n",
            "creating /usr/local/lib/python3.6/dist-packages/python_docx-0.8.10-py3.6.egg\n",
            "Extracting python_docx-0.8.10-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding python-docx 0.8.10 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/python_docx-0.8.10-py3.6.egg\n",
            "Searching for pdfminer.six\n",
            "Reading https://pypi.org/simple/pdfminer.six/\n",
            "Downloading https://files.pythonhosted.org/packages/8a/fd/6e8746e6965d1a7ea8e97253e3d79e625da5547e8f376f88de5d024bacb9/pdfminer.six-20181108-py2.py3-none-any.whl#sha256=f04d029d1d3e58c87da51bdefef2e9a1dbf2d7b63f727dd2a3e36054f5ae96ea\n",
            "Best match: pdfminer.six 20181108\n",
            "Processing pdfminer.six-20181108-py2.py3-none-any.whl\n",
            "Installing pdfminer.six-20181108-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/pdfminer.six-20181108-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding pdfminer.six 20181108 to easy-install.pth file\n",
            "Installing pdf2txt.py script to /usr/local/bin\n",
            "Installing latin2ascii.py script to /usr/local/bin\n",
            "Installing dumppdf.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pdfminer.six-20181108-py3.6.egg\n",
            "Searching for feedparser\n",
            "Reading https://pypi.org/simple/feedparser/\n",
            "Downloading https://files.pythonhosted.org/packages/3f/e2/a8ae28b49bebdffcefff86c915a99ddd2ecc36b74fb7d3beeaec47b6946a/feedparser-6.0.0b1-py2.py3-none-any.whl#sha256=87185443d6e12cf870125bdc9211168c60895e7dd7209b5c082897ddb1b11efb\n",
            "Best match: feedparser 6.0.0b1\n",
            "Processing feedparser-6.0.0b1-py2.py3-none-any.whl\n",
            "Installing feedparser-6.0.0b1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/feedparser-6.0.0b1-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding feedparser 6.0.0b1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/feedparser-6.0.0b1-py3.6.egg\n",
            "Searching for mysqlclient\n",
            "Reading https://pypi.org/simple/mysqlclient/\n",
            "Downloading https://files.pythonhosted.org/packages/4d/38/c5f8bac9c50f3042c8f05615f84206f77f03db79781db841898fde1bb284/mysqlclient-1.4.4.tar.gz#sha256=9c737cc55a5dc8dd3583a942d5a9b21be58d16f00f5fefca4e575e7d9682e98c\n",
            "Best match: mysqlclient 1.4.4\n",
            "Processing mysqlclient-1.4.4.tar.gz\n",
            "Writing /tmp/easy_install-sapsltbt/mysqlclient-1.4.4/setup.cfg\n",
            "Running mysqlclient-1.4.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-sapsltbt/mysqlclient-1.4.4/egg-dist-tmp-fi7vyxmn\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "MySQLdb.__pycache__._mysql.cpython-36: module references __file__\n",
            "creating /usr/local/lib/python3.6/dist-packages/mysqlclient-1.4.4-py3.6-linux-x86_64.egg\n",
            "Extracting mysqlclient-1.4.4-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mysqlclient 1.4.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mysqlclient-1.4.4-py3.6-linux-x86_64.egg\n",
            "Searching for backports.csv\n",
            "Reading https://pypi.org/simple/backports.csv/\n",
            "Downloading https://files.pythonhosted.org/packages/8e/26/a6bd68f13e0f38fbb643d6e497fc3462be83a0b6c4d43425c78bb51a7291/backports.csv-1.0.7-py2.py3-none-any.whl#sha256=21f6e09bab589e6c1f877edbc40277b65e626262a86e69a70137db714eaac5ce\n",
            "Best match: backports.csv 1.0.7\n",
            "Processing backports.csv-1.0.7-py2.py3-none-any.whl\n",
            "Installing backports.csv-1.0.7-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding backports.csv 1.0.7 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/backports.csv-1.0.7-py3.6.egg\n",
            "Searching for zc.lockfile\n",
            "Reading https://pypi.org/simple/zc.lockfile/\n",
            "Downloading https://files.pythonhosted.org/packages/6c/2a/268389776288f0f26c7272c70c36c96dcc0bdb88ab6216ea18e19df1fadd/zc.lockfile-2.0-py2.py3-none-any.whl#sha256=cc33599b549f0c8a248cb72f3bf32d77712de1ff7ee8814312eb6456b42c015f\n",
            "Best match: zc.lockfile 2.0\n",
            "Processing zc.lockfile-2.0-py2.py3-none-any.whl\n",
            "Installing zc.lockfile-2.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/zc.lockfile-2.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding zc.lockfile 2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/zc.lockfile-2.0-py3.6.egg\n",
            "Searching for portend>=2.1.1\n",
            "Reading https://pypi.org/simple/portend/\n",
            "Downloading https://files.pythonhosted.org/packages/0a/f5/0e5fe0bba1450034f023519aed3ca326bc42981475a93e3645ab868f351c/portend-2.5-py2.py3-none-any.whl#sha256=d2dca12e585ce29fc357b31ce424a27c16e2d485029252bbf8ddcc9696207976\n",
            "Best match: portend 2.5\n",
            "Processing portend-2.5-py2.py3-none-any.whl\n",
            "Installing portend-2.5-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/portend-2.5-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding portend 2.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/portend-2.5-py3.6.egg\n",
            "Searching for cheroot>=6.2.4\n",
            "Reading https://pypi.org/simple/cheroot/\n",
            "Downloading https://files.pythonhosted.org/packages/b8/9d/c3ea7e706c13070722a115ca456ae58951dfb0bf01ae2e6b589155dec9fd/cheroot-8.1.0-py2.py3-none-any.whl#sha256=d523a1525258730026aa35b86c8c47c8d0e3892fb89f0f39157d4b32a50edf05\n",
            "Best match: cheroot 8.1.0\n",
            "Processing cheroot-8.1.0-py2.py3-none-any.whl\n",
            "Installing cheroot-8.1.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/cheroot-8.1.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding cheroot 8.1.0 to easy-install.pth file\n",
            "Installing cheroot script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/cheroot-8.1.0-py3.6.egg\n",
            "Searching for pycryptodome\n",
            "Reading https://pypi.org/simple/pycryptodome/\n",
            "Downloading https://files.pythonhosted.org/packages/c1/f1/0ba99559391621280ce24adea245d31bf2eb2f20ac72270eead1813e8d2b/pycryptodome-3.9.0-cp36-cp36m-manylinux1_x86_64.whl#sha256=6840c9881e528224ebf72b3f73b3d11baf399e265106c9f4d9bae4f09615a93a\n",
            "Best match: pycryptodome 3.9.0\n",
            "Processing pycryptodome-3.9.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing pycryptodome-3.9.0-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pycryptodome 3.9.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pycryptodome-3.9.0-py3.6-linux-x86_64.egg\n",
            "Searching for sgmllib3k\n",
            "Reading https://pypi.org/simple/sgmllib3k/\n",
            "Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz#sha256=7868fb1c8bfa764c1ac563d3cf369c381d1325d36124933a726f29fcdaa812e9\n",
            "Best match: sgmllib3k 1.0.0\n",
            "Processing sgmllib3k-1.0.0.tar.gz\n",
            "Writing /tmp/easy_install-kc058kds/sgmllib3k-1.0.0/setup.cfg\n",
            "Running sgmllib3k-1.0.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-kc058kds/sgmllib3k-1.0.0/egg-dist-tmp-w3k_1n6w\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving sgmllib3k-1.0.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sgmllib3k 1.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sgmllib3k-1.0.0-py3.6.egg\n",
            "Searching for tempora>=1.8\n",
            "Reading https://pypi.org/simple/tempora/\n",
            "Downloading https://files.pythonhosted.org/packages/5c/12/4c97c44e5c9d111649e363353a4ca3ece9c6cc04b11cc48540f26e42d7b9/tempora-1.14.1-py2.py3-none-any.whl#sha256=d28a03d2f64ee81aec6e6bff374127ef306fe00c1b7e27c7ff1618344221a699\n",
            "Best match: tempora 1.14.1\n",
            "Processing tempora-1.14.1-py2.py3-none-any.whl\n",
            "Installing tempora-1.14.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/tempora-1.14.1-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding tempora 1.14.1 to easy-install.pth file\n",
            "Installing calc-prorate script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/tempora-1.14.1-py3.6.egg\n",
            "Searching for jaraco.functools\n",
            "Reading https://pypi.org/simple/jaraco.functools/\n",
            "Downloading https://files.pythonhosted.org/packages/12/a4/3e7366d0f5e75dcad7be88524c8cbd0f3a9fb1db243269550981740c57fe/jaraco.functools-2.0-py2.py3-none-any.whl#sha256=e9e377644cee5f6f9128b4dab1631fca74981236e95a255f80e4292bcd2b5284\n",
            "Best match: jaraco.functools 2.0\n",
            "Processing jaraco.functools-2.0-py2.py3-none-any.whl\n",
            "Installing jaraco.functools-2.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/jaraco.functools-2.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding jaraco.functools 2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/jaraco.functools-2.0-py3.6.egg\n",
            "Searching for requests==2.21.0\n",
            "Best match: requests 2.21.0\n",
            "Adding requests 2.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for nltk==3.2.5\n",
            "Best match: nltk 3.2.5\n",
            "Adding nltk 3.2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.1\n",
            "Best match: scipy 1.3.1\n",
            "Adding scipy 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.5\n",
            "Best match: numpy 1.16.5\n",
            "Adding numpy 1.16.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lxml==4.2.6\n",
            "Best match: lxml 4.2.6\n",
            "Adding lxml 4.2.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for beautifulsoup4==4.6.3\n",
            "Best match: beautifulsoup4 4.6.3\n",
            "Adding beautifulsoup4 4.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2019.9.11\n",
            "Best match: certifi 2019.9.11\n",
            "Adding certifi 2019.9.11 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.8\n",
            "Best match: idna 2.8\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for more-itertools==7.2.0\n",
            "Best match: more-itertools 7.2.0\n",
            "Adding more-itertools 7.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for sortedcontainers==2.1.0\n",
            "Best match: sortedcontainers 2.1.0\n",
            "Adding sortedcontainers 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.2.0\n",
            "Best match: setuptools 41.2.0\n",
            "Adding setuptools 41.2.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for Pattern==3.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLyGTa37HyIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "f19ec13d-ad66-4ad2-ae0b-adfa9eb5de56"
      },
      "source": [
        "### IMPORT STATEMENTS ###\n",
        "import re\n",
        "import nltk\n",
        "from html.parser import HTMLParser\n",
        "from pprint import pprint\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from pattern.text.en import tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import gutenberg\n",
        "from operator import itemgetter\n",
        "import string\n",
        "from nltk.collocations import BigramAssocMeasures\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.collocations import TrigramAssocMeasures\n",
        "import itertools\n",
        "from gensim import corpora, models\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "wnl = WordNetLemmatizer()\n",
        "# from contractions import CONTRACTION_MAP"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6X47hSelHSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## REGEX CODE SNIPPET ###\n",
        "s = u'H\\u00e8llo'\n",
        "print(re.findall(r'\\w+', s, re.UNICODE))\n",
        "pattern = 'python'\n",
        "s1 = 'Python is an excellent language'\n",
        "s2 = 'I love the python language. I used python to build anaconda'\n",
        "print(re.match(pattern, s1, flags = re.IGNORECASE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSF__00Zm8kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text = \"We won't discuss briefly about the basic syntax, structure and\\\n",
        "design philosophies. There is a defined hierarchical syntax for Python code\\\n",
        "which you should remember when writing code! Python is a really powerful\\\n",
        "programming language!\"\n",
        "print(len(sample_text))\n",
        "default_st = nltk.sent_tokenize\n",
        "default_wt = nltk.word_tokenize\n",
        "sample_sentences = default_st(text = sample_text)\n",
        "words = default_wt(sample_sentences[0])\n",
        "pprint(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqOCN4Vv28qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibwk3PwlItEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### EXTRACT SENTENCES ###\n",
        "html_parser = HTMLParser()\n",
        "def parse_document(document):\n",
        "  document = re.sub('\\n',' ', document)\n",
        "  if isinstance(document, str):\n",
        "    document = document\n",
        "  elif isinstance(document, unicode):\n",
        "    return unicode.normalize('NFKD', document).encode('ascii', 'ignore')\n",
        "  else:\n",
        "    raise ValueError('Document format not supported')\n",
        "  document = document.strip()\n",
        "  sentences = nltk.sent_tokenize(document)\n",
        "  sentences = [sentence.strip() for sentence in sentences]\n",
        "  return sentences\n",
        "\n",
        "def pos_tagger(text):\n",
        "    def penn_to_wn_tags(pos_tag):\n",
        "        if pos_tag.startswith('J'):\n",
        "            return wn.ADJ\n",
        "        elif pos_tag.startswith('V'):\n",
        "            return wn.VERB\n",
        "        elif pos_tag.startswith('N'):\n",
        "            return wn.NOUN\n",
        "        elif pos_tag.startswith('R'):\n",
        "            return wn.ADV\n",
        "        else:\n",
        "            return None\n",
        "    tagged_text = tag(text)\n",
        "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
        "                         for word, pos_tag in\n",
        "                         tagged_text]\n",
        "    return tagged_lower_text\n",
        "\n",
        "def tokenize_word(sentences):\n",
        "  words = nltk.word_tokenize(sentences) \n",
        "  words = [word.strip() for word in words]\n",
        "  return words\n",
        "\n",
        "def remove_characters_after_tokenization(tokens):\n",
        "  pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
        "  filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
        "  return filtered_tokens\n",
        "### Unescaping Characters ###\n",
        "\n",
        "def chunkdown(sentences, grammar = r'NP:{<DT>?<JJ>* <NN.*>+}'):\n",
        "  all_chunks = []\n",
        "  chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
        "  for sentence in sentences:\n",
        "    tagged_sents = nltk.pos_tag_sents([nltk.word_tokenize(sentence)])\n",
        "    chunks = [chunker.parse(tagged_sent) for tagged_sent in tagged_sents]\n",
        "    wtc_sents = [nltk.chunk.tree2conlltags(chunk) for chunk in chunks]\n",
        "    print(wtc_sents)\n",
        "    wtc_group = wtc_sents[0]\n",
        "    flattened_chunks = list(itertools.chain.from_iterable(wtc_sent for wtc_sent in wtc_sents))\n",
        "    valid_chunks_tagged = [(status, [wtc for wtc in chunk]) for status, chunk in itertools.groupby(flattened_chunks, lambda chunk: chunk!='0')]\n",
        "    valid_chunks = [' '.join(word.lower() for word, tag, chunk in wtc_group if word.lower() not in stopword_list) for status, wtc_group in valid_chunks_tagged if status]\n",
        "    all_chunks.append(valid_chunks)\n",
        "  return all_chunks\n",
        "\n",
        "def expand_contractions(sentence, contraction_mapping):\n",
        "  contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), flags = re.IGNORECASE|re.DOTALL)\n",
        "  def expand_match(contraction):\n",
        "    match = contraction.group(0)\n",
        "    first_char = match[0]\n",
        "    expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
        "    expanded_contraction = first_char + expanded_contraction[1:]\n",
        "    return expanded_contraction\n",
        "  expanded_sentence = contractions_pattern.sub(expand_match, sentence)\n",
        "  return expanded_sentence\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    tokens = tokenize_word(text)\n",
        "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
        "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text\n",
        "    \n",
        "    \n",
        "def remove_stopwords(text):\n",
        "    tokens = tokenize_word(text)\n",
        "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    \n",
        "    pos_tagged_text = pos_tagger(text)\n",
        "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
        "                         else word                     \n",
        "                         for word, pos_tag in pos_tagged_text]\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
        "    return lemmatized_text\n",
        "\n",
        "def normalize_corpus(corpus, lemmatize = True, tokenize = False):\n",
        "  normalized_corpus = []\n",
        "  for text in corpus:\n",
        "    text = unescape_html(html_parser, text)\n",
        "    text = expand_contractions(text, CONTRACTION_MAP)\n",
        "    if lemmatize:\n",
        "        text = lemmatize_text(text)\n",
        "    else:\n",
        "        text = text.lower()\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_stopwords(text)\n",
        "    if tokenize: \n",
        "      text = tokenize_text(text)\n",
        "      normalized_corpus.append(text)\n",
        "    else:\n",
        "      normalized_corpus.append(text)\n",
        "    return normalized_corpus\n",
        "\n",
        "def convert_to_vectors(documents, feature_type = 'tfidf'):\n",
        "  feature_type = feature_type.lower().strip()\n",
        "  if feature_type == 'binary':\n",
        "    vectorizer = CountVectorizer(binary = True, min_df = 1, ngram_range = (1,1))\n",
        "  elif feature_type == 'frequency':\n",
        "    vectorizer = CountVectorizer(binary = False, min_df = 1, ngram_range = (1,1))\n",
        "  elif feature_type == 'tfidf':\n",
        "    vectorizer = TfidfVectorizer(min_df = 1, ngram_range=(1,1))\n",
        "  else:\n",
        "    raise Exception(\"Mistake in feature type\")\n",
        "  feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
        "  return vectorizer, feature_matrix\n",
        "\n",
        "def tfidf_transformer(bag_of_words):\n",
        "  transformer = TfidfTransformer(norm = 'l2', smooth_idf = True, use_idf = True)\n",
        "  tfidf_matrix = transformer.fit_transform(bag_of_words)\n",
        "  return transformer, tfidf_matrix\n",
        "\n",
        "def flatten_corpus(corpus):\n",
        "  return ' '.join([document.strip() for document in corpus])\n",
        "\n",
        "def unescape_html(parser, text):\n",
        "  return parser.unescape(text)\n",
        "\n",
        "def get_ngrams(text, n):\n",
        "  ngrams = zip(*[sequence[index:] for index in range(n)])\n",
        "  return ngrams\n",
        "\n",
        "def top_ngrams(corpus, ngram_val = 1, limit = 5):\n",
        "  corpus = flatten_corpus(corpus)\n",
        "  tokens = nltk.word_tokenize(corpus)\n",
        "  ngrams = get_ngrams(tokens, ngram_val)\n",
        "  ngrams_frequency = nltk.FreqDist(ngrams)\n",
        "  sorted_ngrams = sorted(ngrams_frequency, key = itemgetter(1), reverse = True)\n",
        "  top_sorted_ngrams = sorted_ngrams[0:limit]\n",
        "  top_sorted_ngrams = [(' '.join(text), freq) for text, freq in top_sorted_ngrams]\n",
        "  return top_sorted_ngrams "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XQD9Jd524jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TEST FUNCTIONS ###\n",
        "sentence = \"The quick brown fox jumped on the lazy dogs.\"\n",
        "print(pos_tag_text(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRjMcZt2nW8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fcc0d853-4633-42de-c256-0e02683d8356"
      },
      "source": [
        "print(string.punctuation)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0d98ef105330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnxVpEuCluX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b368beef-74c0-4b60-d391-1bcfaa4562f4"
      },
      "source": [
        "alice = gutenberg.sents(fileids = 'carroll-alice.txt')\n",
        "alice = [' '.join(ts) for ts in alice]\n",
        "norm_alice = list(filter(None, normalize_corpus(alice, lemmatize = False)))\n",
        "print(norm_alice[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice adventures wonderland lewis carroll 1865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:117: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MguWW5482F9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bcfind = BigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
        "bigram_measures = BigramAssocMeasures()\n",
        "bcfind.nbest(bigram_measures.pmi, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_7GBOeKaasG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "325da5ae-4976-42ab-a9d5-9de3e8db3944"
      },
      "source": [
        "toy_text = \"\"\"\n",
        "Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.\n",
        "The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers learn automatically without human intervention or assistance and adjust actions accordingly.  \n",
        "\"\"\"\n",
        "sentences = parse_document(toy_text)\n",
        "valid_chunks = chunkdown(sentences)\n",
        "for chunk in valid_chunks:\n",
        "  print(''.join(chunk))\n",
        "  print()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('Machine', 'NN', 'B-NP'), ('learning', 'NN', 'I-NP'), ('is', 'VBZ', 'O'), ('an', 'DT', 'B-NP'), ('application', 'NN', 'I-NP'), ('of', 'IN', 'O'), ('artificial', 'JJ', 'B-NP'), ('intelligence', 'NN', 'I-NP'), ('(', '(', 'O'), ('AI', 'NNP', 'B-NP'), (')', ')', 'O'), ('that', 'WDT', 'O'), ('provides', 'VBZ', 'O'), ('systems', 'NNS', 'B-NP'), ('the', 'DT', 'B-NP'), ('ability', 'NN', 'I-NP'), ('to', 'TO', 'O'), ('automatically', 'RB', 'O'), ('learn', 'VB', 'O'), ('and', 'CC', 'O'), ('improve', 'VB', 'O'), ('from', 'IN', 'O'), ('experience', 'NN', 'B-NP'), ('without', 'IN', 'O'), ('being', 'VBG', 'O'), ('explicitly', 'RB', 'O'), ('programmed', 'VBN', 'O'), ('.', '.', 'O')]]\n",
            "[[('Machine', 'NN', 'B-NP'), ('learning', 'VBG', 'O'), ('focuses', 'NNS', 'B-NP'), ('on', 'IN', 'O'), ('the', 'DT', 'B-NP'), ('development', 'NN', 'I-NP'), ('of', 'IN', 'O'), ('computer', 'NN', 'B-NP'), ('programs', 'NNS', 'I-NP'), ('that', 'WDT', 'O'), ('can', 'MD', 'O'), ('access', 'NN', 'B-NP'), ('data', 'NNS', 'I-NP'), ('and', 'CC', 'O'), ('use', 'VB', 'O'), ('it', 'PRP', 'O'), ('learn', 'VB', 'O'), ('for', 'IN', 'O'), ('themselves', 'PRP', 'O'), ('.', '.', 'O')]]\n",
            "[[('The', 'DT', 'B-NP'), ('process', 'NN', 'I-NP'), ('of', 'IN', 'O'), ('learning', 'VBG', 'O'), ('begins', 'NNS', 'B-NP'), ('with', 'IN', 'O'), ('observations', 'NNS', 'B-NP'), ('or', 'CC', 'O'), ('data', 'NNS', 'B-NP'), (',', ',', 'O'), ('such', 'JJ', 'O'), ('as', 'IN', 'O'), ('examples', 'NNS', 'B-NP'), (',', ',', 'O'), ('direct', 'JJ', 'B-NP'), ('experience', 'NN', 'I-NP'), (',', ',', 'O'), ('or', 'CC', 'O'), ('instruction', 'NN', 'B-NP'), (',', ',', 'O'), ('in', 'IN', 'O'), ('order', 'NN', 'B-NP'), ('to', 'TO', 'O'), ('look', 'VB', 'O'), ('for', 'IN', 'O'), ('patterns', 'NNS', 'B-NP'), ('in', 'IN', 'O'), ('data', 'NNS', 'B-NP'), ('and', 'CC', 'O'), ('make', 'VB', 'O'), ('better', 'JJR', 'O'), ('decisions', 'NNS', 'B-NP'), ('in', 'IN', 'O'), ('the', 'DT', 'B-NP'), ('future', 'NN', 'I-NP'), ('based', 'VBN', 'O'), ('on', 'IN', 'O'), ('the', 'DT', 'B-NP'), ('examples', 'NNS', 'I-NP'), ('that', 'IN', 'O'), ('we', 'PRP', 'O'), ('provide', 'VBP', 'O'), ('.', '.', 'O')]]\n",
            "[[('The', 'DT', 'B-NP'), ('primary', 'JJ', 'I-NP'), ('aim', 'NN', 'I-NP'), ('is', 'VBZ', 'O'), ('to', 'TO', 'O'), ('allow', 'VB', 'O'), ('the', 'DT', 'B-NP'), ('computers', 'NNS', 'I-NP'), ('learn', 'VBP', 'O'), ('automatically', 'RB', 'O'), ('without', 'IN', 'O'), ('human', 'JJ', 'B-NP'), ('intervention', 'NN', 'I-NP'), ('or', 'CC', 'O'), ('assistance', 'NN', 'B-NP'), ('and', 'CC', 'O'), ('adjust', 'JJ', 'B-NP'), ('actions', 'NNS', 'I-NP'), ('accordingly', 'RB', 'O'), ('.', '.', 'O')]]\n",
            "machine learning application artificial intelligence ( ai ) provides systems ability automatically learn improve experience without explicitly programmed .\n",
            "\n",
            "machine learning focuses development computer programs access data use learn .\n",
            "\n",
            "process learning begins observations data , examples , direct experience , instruction , order look patterns data make better decisions future based examples provide .\n",
            "\n",
            "primary aim allow computers learn automatically without human intervention assistance adjust actions accordingly .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsIjKCIOd8Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEvVTzPdd8FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}